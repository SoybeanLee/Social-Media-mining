{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPkEASb50vqImCxGQ5g9tM7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OkluO2irPDU3"},"outputs":[],"source":["#BERT model\n","\n","\n","#!pip install datasets\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","import torch\n","from datasets import Dataset\n","import json\n","\n","# Load and preprocess the dataset\n","def preprocess_data(json_file):\n","    data = []\n","    with open(json_file, 'r') as f:\n","        for line in f:\n","            try:\n","                data.append(json.loads(line))\n","            except json.JSONDecodeError as e:\n","                print(f\"Skipping invalid line: {line.strip()} due to error: {e}\")\n","                continue\n","    texts = [item['text'] for item in data]\n","    labels = [1 if sum(label[0] for label in item['composite_toxic']) > 2 else 0 for item in data]\n","    return Dataset.from_dict({'text': texts, 'label': labels})\n","\n","dataset = preprocess_data('/content/z639_assignment1_training.json')\n","\n","# Tokenize the text\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","def tokenize_function(examples):\n","    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)  # Reduced max_length\n","\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)\n","\n","# Load the model\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=1,  # Further reduced epochs\n","    per_device_train_batch_size=16,  # Try increasing if memory allows\n","    evaluation_strategy=\"epoch\",\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    fp16=True  # Use mixed precision\n",")\n","\n","# Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets,\n","    eval_dataset=tokenized_datasets\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Save the trained model and tokenizer\n","model.save_pretrained('/content/saved_model')\n","tokenizer.save_pretrained('/content/saved_model')\n","\n","from google.colab import files\n","import shutil\n","\n","# Zip the saved model directory\n","shutil.make_archive('/content/saved_model', 'zip', '/content/saved_model')\n","\n","# Download the zipped model directory\n","files.download('/content/saved_model.zip')\n","\n","#Test data\n","# Load the tokenizer and trained model\n","tokenizer = DistilBertTokenizer.from_pretrained('/content/saved_model')\n","model = DistilBertForSequenceClassification.from_pretrained('/content/saved_model')\n","\n","# Function to load and preprocess test data\n","def load_test_data(json_file):\n","    with open(json_file, 'r') as f:\n","        data = [json.loads(line) for line in f]\n","    texts = [item['text'] for item in data]  # Extract the text field\n","    return texts\n","\n","# Load test data\n","test_texts = load_test_data('/content/z639_assignment1_test.json')\n","\n","# Tokenize the test data\n","inputs = tokenizer(test_texts, return_tensors='pt', padding=True, truncation=True, max_length=128)\n","\n","# Put the model in evaluation mode\n","model.eval()\n","\n","# Make predictions\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","\n","# Get predicted labels\n","predictions = torch.argmax(outputs.logits, dim=-1)\n","\n","import pandas as pd\n","import json\n","\n","# Load the test data with platform_id\n","def load_test_data_with_id(json_file):\n","    data = []\n","    with open(json_file, 'r') as f:\n","        for line in f:\n","            try:\n","                data.append(json.loads(line))  # Load each line as a separate JSON object\n","            except json.JSONDecodeError as e:\n","                print(f\"Skipping invalid line: {line.strip()} due to error: {e}\")\n","                continue\n","    texts = [item['text'] for item in data]  # Extract the text field\n","    platform_ids = [item['platform_id'] for item in data]  # Extract the platform_id field\n","    return texts, platform_ids\n","\n","# Assuming 'predictions' and 'test_texts' are defined as before\n","test_texts, platform_ids = load_test_data_with_id('/content/z639_assignment1_test.json')\n","\n","# Create a DataFrame to save predictions\n","df = pd.DataFrame({\n","    'platform_id': platform_ids,\n","    'prediction': [True if pred == 1 else False for pred in predictions]\n","})\n","\n","# Save the results to a CSV file\n","df.to_csv('/content/predictions_with_id.csv', index=False)\n","\n","# Print confirmation\n","print(\"Predictions saved to /content/predictions_with_id.csv\")\n","\n","#Evaluate the BERT results\n","from sklearn.metrics import classification_report, accuracy_score\n","import json\n","\n","# Load the true labels from your test dataset (assuming the labels are present)\n","def load_true_labels(json_file):\n","    with open(json_file, 'r') as f:\n","        data = [json.loads(line) for line in f]\n","    # Instead of relying on 'composite_toxic', adjust to the structure of your test data\n","    # For example, if your test data has a 'label' key directly, use:\n","    # labels = [item['label'] for item in data]\n","    # However, since we do not have information about the actual structure of the test data,\n","    # here's a placeholder that assumes a list called 'toxicity_level' with a single value\n","    labels = [1 if item.get('toxicity_level', [0])[0] > 0.5 else 0 for item in data]\n","    return labels\n","\n","# Assuming 'predictions' and 'test_texts' are defined as before\n","true_labels = load_true_labels('/content/z639_assignment1_test.json')\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(true_labels, predictions)\n","print(f\"Accuracy: {accuracy:.2f}\")\n","\n","# Detailed classification report\n","report = classification_report(true_labels, predictions, target_names=['Not Toxic', 'Toxic'])\n","print(report)"]},{"cell_type":"code","source":["#SVM model\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","\n","# Load and preprocess the dataset\n","def preprocess_data_svm(json_file):\n","    import json\n","    # Try to fix the JSON file by reading it as a list of JSON objects\n","    with open(json_file, 'r') as f:\n","        data = []\n","        for line in f:\n","            if line.strip():  # Skip empty lines\n","                try:\n","                    data.append(json.loads(line))\n","                except json.JSONDecodeError as e:\n","                    print(f\"Skipping invalid JSON line: {line.strip()}\")\n","                    print(f\"Error: {e}\")\n","    texts = [item['text'] for item in data]\n","    labels = [1 if sum(label[0] for label in item['composite_toxic']) > 2 else 0 for item in data]\n","    return texts, labels\n","\n","texts, labels = preprocess_data_svm('z639_assignment1_training.json')\n","\n","# Vectorization\n","vectorizer = TfidfVectorizer(max_features=5000)\n","X = vectorizer.fit_transform(texts)\n","\n","# Split the dataset\n","X_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.2, random_state=42)\n","\n","# Train SVM\n","svm_model = SVC(kernel='linear')\n","svm_model.fit(X_train, y_train)\n","\n","# Evaluate\n","y_pred = svm_model.predict(X_val)\n","print(classification_report(y_val, y_pred))\n","\n","import joblib\n","\n","# Save the trained model\n","joblib.dump(svm_model, '/content/svm_model.pkl')\n","\n","# Save the TF-IDF vectorizer\n","joblib.dump(vectorizer, '/content/tfidf_vectorizer.pkl')\n","\n","import json\n","import pandas as pd\n","import joblib\n","\n","# Load the test data with platform_id\n","def load_test_data_with_id(json_file):\n","    data = []\n","    with open(json_file, 'r') as f:\n","        for line in f:\n","            if line.strip():  # Skip empty lines\n","                try:\n","                    data.append(json.loads(line))\n","                except json.JSONDecodeError as e:\n","                    print(f\"Skipping invalid JSON line: {line.strip()}\")\n","                    print(f\"Error: {e}\")\n","    texts = [item['text'] for item in data]  # Extract the text field\n","    platform_ids = [item['platform_id'] for item in data]  # Extract the platform_id field\n","    return texts, platform_ids\n","\n","# Load the model and vectorizer\n","svm_model_loaded = joblib.load('/content/svm_model.pkl')\n","vectorizer_loaded = joblib.load('/content/tfidf_vectorizer.pkl')\n","\n","# Load and transform the test data\n","test_texts, platform_ids = load_test_data_with_id('/content/z639_assignment1_test.json')\n","X_test = vectorizer_loaded.transform(test_texts)\n","\n","# Make predictions\n","predictions = svm_model_loaded.predict(X_test)\n","\n","# Create a DataFrame to save predictions\n","df = pd.DataFrame({\n","    'platform_id': platform_ids,\n","    'prediction': [True if pred == 1 else False for pred in predictions]\n","})\n","\n","# Save the results to a CSV file\n","df.to_csv('/content/predictions_with_id.csv', index=False)\n","\n","# Print confirmation\n","print(\"Predictions saved to /content/predictions_with_id.csv\")\n","\n","\n","#Evaluate the SVM results\n","import json\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Load the true labels from your test dataset\n","def load_true_labels(json_file):\n","    with open(json_file, 'r') as f:\n","        data = []\n","        # Read the file line by line and parse each line as a JSON object\n","        for line in f:\n","            # Skip empty lines\n","            if line.strip():\n","                try:\n","                    data.append(json.loads(line))\n","                except json.JSONDecodeError as e:\n","                    print(f\"Skipping invalid JSON line: {line.strip()}\")\n","                    print(f\"Error: {e}\")\n","    # Check if 'composite_toxic' key exists before accessing it\n","    labels = [1 if sum(label[0] for label in item.get('composite_toxic', [])) > 2 else 0 for item in data]\n","    return labels\n","\n","# Load true labels\n","true_labels = load_true_labels('/content/z639_assignment1_test.json')\n","\n","# Assuming 'predictions' are already defined as before from the SVM model\n","# Calculate accuracy\n","accuracy = accuracy_score(true_labels, predictions)\n","print(f\"Accuracy: {accuracy:.2f}\")\n","\n","# Detailed classification report\n","report = classification_report(true_labels, predictions, target_names=['Not Toxic', 'Toxic'])\n","print(report)"],"metadata":{"id":"yZ7WDWt4PH8m"},"execution_count":null,"outputs":[]}]}